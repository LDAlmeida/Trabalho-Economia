# -*- coding: utf-8 -*-
"""Trabalho_Economia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A7AYxy0ortRjGalRHc6nCfHZ5BL9bL-g
"""

formacoes = ['Banco de Dados', 'Ciência da Computação', 'Ciência e Tecnologia',
             'Computação', 'Estatística', 'Física',
             'Gestão da Tecnologia da Informação', 'Informática',
             'Informática Biomédica', 'Matemática', 'Nanotecnologia', 'Química',
             'Redes de Computadores', 'Segurança da Informação',
             'Sistemas de Informação', 'Sistemas para Internet',
             'Processos Gerenciais', 'Segurança Pública', 'Turismo']
dic_targets = dict(zip(range(0, len(formacoes)), formacoes))

import pandas as pd
pd.set_option('display.max_columns', None)

features = ['Quantos empregos já teve?',
            'Quantos certificações tem na área de tecnologia?',
            'Quantos certificações tem na área de gestão?',
            'Quantos certificações tem na área de segurança do trabalho?',
            'Quantas horas de cursos tem na área de tecnologia?',
            'Quantas horas de cursos tem na área de gestão?',
            'Quantas horas de cursos tem na área de segurança do trabalho?',
            'Quantas graduações você tem?',
            'Quantas vezes já foi mandado embora?',
            'Quantos papéis já publicou na área de tecnologia da informação?',
            'Quantas vezes já se sentiu discriminado?',
            'Quantas vezes já foi casado?',
            'Quantos filhos você tem?',
            'Quanto você ou quer receber?',
            'Quantas bolas de tenis cabem em uma limosine?']

from sklearn.datasets import make_classification
data = make_classification(n_samples=50000, n_features=15, n_informative=10, n_classes=19, random_state=420)
df_explicativas = pd.DataFrame(data[0],
                               columns = features)
df_target = pd.DataFrame(data[1], columns=['target'])
df_target['target'] = df_target['target'].apply(lambda x: dic_targets[x])

df_explicativas.head(2)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df_explicativas, df_target, test_size=0.33, random_state=420)

from sklearn.ensemble import RandomForestClassifier
rfr = RandomForestClassifier(n_estimators=40, max_depth=6, random_state=420)
rfr.fit(X_train, y_train.values)
y_preds = rfr.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_preds))

df_importancia = pd.DataFrame(index=features,
                              data=rfr.feature_importances_,
                              columns=['Importância'])

df_importancia.sort_values(by='Importância', ascending=False).style.bar()

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
df_nao_padronizado = pd.read_csv('dados_manuais.csv')
df_padronizado = ss.fit_transform(df_nao_padronizado)

## Se o ss já estiver fittado:
entradas = [[2,3,1,0,570,60,0,1,0,0,1,0,0,2500,1500]]
df_novo_nao_padronizado = pd.DataFrame(data=entradas, columns=features)
df_novo_padronizado = ss.transform(df_novo_nao_padronizado)

df_novo_padronizado

rfr.predict(df_novo_padronizado[0].reshape(1, -1))[0]

# https://pypi.org/project/pybaobabdt/
# https://github.com/parrt/dtreeviz
# https://www.youtube.com/watch?v=J4Wdy0Wc_xQ